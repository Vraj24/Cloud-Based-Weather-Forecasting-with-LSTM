{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4891a39-48d1-4bec-aa5c-a42612e86201",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22356\\2367336747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# mypy: allow-untyped-defs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m from torch.nn.parameter import (  # usort: skip\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mBuffer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mParameter\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mUninitializedBuffer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mUninitializedBuffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parameter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_disabled_torch_function_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import boto3\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install seaborn\n",
    "# import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# === CONFIG ===\n",
    "bucket = \"kinesis-lambda-s3-bucket1\"\n",
    "key = \"cleaned/cleaned_weather_dataset.csv\"\n",
    "local_file = \"cleaned_weather_dataset.csv\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(bucket, key, local_file)\n",
    "\n",
    "# === Load & Preprocess Data ===\n",
    "df = pd.read_csv(local_file)\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# === Step 3: Preprocess Data and Extract Last 14 Days ===\n",
    "features = ['AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT01', 'WT08']\n",
    "all_data = df[features].values\n",
    "scaler = MinMaxScaler()\n",
    "scaled_all = scaler.fit_transform(all_data)\n",
    "future_input = scaled_all[-14:]\n",
    "\n",
    "# === Step 4: Define Model ===\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h, c) = self.encoder(x)\n",
    "        decoder_input = x[:, -1:, :]\n",
    "        outputs = []\n",
    "        for _ in range(7):  # 7-day forecast\n",
    "            out, (h, c) = self.decoder(decoder_input, (h, c))\n",
    "            step_output = self.output_layer(out[:, -1, :])\n",
    "            outputs.append(step_output.unsqueeze(1))\n",
    "            decoder_input = step_output.unsqueeze(1)\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "# === Step 5: Load Pre-trained Model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMForecast(input_size=11, hidden_size=64, output_size=11).to(device)\n",
    "model.load_state_dict(torch.load(\"lstm_multivariate_7day.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === Step 6: Forecast Next 7 Days ===\n",
    "input_tensor = torch.FloatTensor(future_input).unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    prediction = model(input_tensor).cpu().numpy().squeeze()\n",
    "\n",
    "predicted = scaler.inverse_transform(prediction)\n",
    "\n",
    "# === Step 7: Generate Date Headings ===\n",
    "last_date = df['date'].iloc[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=7)\n",
    "day_labels = [f\"Day {i+1}\" for i in range(7)]\n",
    "\n",
    "df_pred = pd.DataFrame(predicted, columns=features)\n",
    "df_pred.insert(0, \"Date\", future_dates)\n",
    "df_pred.insert(1, \"Day\", day_labels)\n",
    "\n",
    "print(\"ðŸ“Š Forecasted Weather Data for the Next 7 Days:\")\n",
    "display(df_pred)\n",
    "\n",
    "# === Step 8: Visualize Each Feature ===\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(df_pred['Day'], df_pred[feature], marker='o', label='Predicted')\n",
    "    plt.title(f'{feature} â€” 7-Day Forecast')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb8a08-87de-4b35-82f6-a95738376e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
