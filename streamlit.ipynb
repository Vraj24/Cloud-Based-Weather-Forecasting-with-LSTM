{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d13f76-91b1-4714-98c0-e81e71491c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# === Step 1: Load and preprocess dataset ===\n",
    "#df = pd.read_csv(\"cleaned_weather_dataset.csv\")\n",
    "#df = pd.read_csv(r\"C:\\Users\\DELL\\main\\cleaned_weather_dataset.csv\")\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\main\\cleaned_weather_dataset.csv\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date')\n",
    "\n",
    "features = ['AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT01', 'WT08']\n",
    "data = df[features].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "INPUT_DAYS = 14\n",
    "PREDICT_DAYS = 7\n",
    "\n",
    "# === Step 2: Create Dataset ===\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data) - INPUT_DAYS - PREDICT_DAYS\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+INPUT_DAYS]\n",
    "        y = self.data[idx+INPUT_DAYS:idx+INPUT_DAYS+PREDICT_DAYS]\n",
    "        return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "\n",
    "dataset = WeatherDataset(scaled_data)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# === Step 3: Define LSTM model ===\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h, c) = self.encoder(x)\n",
    "        decoder_input = x[:, -1:, :]\n",
    "        outputs = []\n",
    "        for _ in range(PREDICT_DAYS):\n",
    "            out, (h, c) = self.decoder(decoder_input, (h, c))\n",
    "            step_output = self.output_layer(out[:, -1, :])\n",
    "            outputs.append(step_output.unsqueeze(1))\n",
    "            decoder_input = step_output.unsqueeze(1)\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "# === Step 4: Train the model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMForecast(input_size=11, hidden_size=64, output_size=11).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"🧠 Starting training...\")\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss / len(loader):.5f}\")\n",
    "\n",
    "# === Step 5: Save model weights ===\n",
    "torch.save(model.state_dict(), \"lstm_multivariate_7day.pth\")\n",
    "print(\"✅ Model trained and saved as lstm_multivariate_7day.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046d2a7-7d0c-4a50-8d53-e3d33f0239f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112c116-5633-42bc-aedd-5550d17b4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# === Step 1: Load dataset ===\n",
    "df = pd.read_csv(\"cleaned_weather_dataset.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "features = ['AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT01', 'WT08']\n",
    "data = df[features].values\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "\n",
    "INPUT_DAYS = 14\n",
    "PREDICT_DAYS = 7\n",
    "\n",
    "# === Step 2: Dataset class ===\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, sequence):\n",
    "        self.sequence = sequence\n",
    "    def __len__(self):\n",
    "        return len(self.sequence) - INPUT_DAYS - PREDICT_DAYS\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.sequence[idx:idx+INPUT_DAYS]\n",
    "        y = self.sequence[idx+INPUT_DAYS:idx+INPUT_DAYS+PREDICT_DAYS]\n",
    "        return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "\n",
    "dataset = WeatherDataset(scaled)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# === Step 3: Define LSTM model ===\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h, c) = self.encoder(x)\n",
    "        decoder_input = x[:, -1:, :]\n",
    "        outputs = []\n",
    "        for _ in range(PREDICT_DAYS):\n",
    "            out, (h, c) = self.decoder(decoder_input, (h, c))\n",
    "            step = self.output_layer(out[:, -1, :])\n",
    "            outputs.append(step.unsqueeze(1))\n",
    "            decoder_input = step.unsqueeze(1)\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "# === Step 4: Train ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMForecast(input_size=11, hidden_size=64, output_size=11).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"🔄 Starting training...\")\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss / len(loader):.5f}\")\n",
    "\n",
    "# === Step 5: Save weights ===\n",
    "torch.save(model.state_dict(), \"lstm_multivariate_7day.pth\")\n",
    "print(\"✅ Model trained and saved as lstm_multivariate_7day.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c0f171-54d2-473f-ac44-a822f5cfee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 19:59:22.921 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:22.963 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\DELL\\anaconda3\\envs\\ecc-env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-29 19:59:22.963 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.045 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 19:59:23.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Day'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ecc-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Day'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m st.subheader(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - 7-Day Forecast\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m fig, ax = plt.subplots()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m ax.plot(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDay\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, df[feature], marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m ax.set_title(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m over the Next 7 Days\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m ax.set_xlabel(\u001b[33m\"\u001b[39m\u001b[33mDay\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ecc-env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ecc-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Day'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load cleaned forecast data\n",
    "#df = pd.read_csv(\"forecast_7day.csv\")  # replace with your actual filename\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\main\\cleaned_weather_dataset.csv\")\n",
    "\n",
    "st.title(\"🌦️ 7-Day Weather Forecast Dashboard\")\n",
    "\n",
    "st.dataframe(df.style.format(precision=2))\n",
    "\n",
    "# Plot each feature\n",
    "features = ['AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT01', 'WT08']\n",
    "selected = st.multiselect(\"Select features to plot:\", features, default=features[:3])\n",
    "\n",
    "for feature in selected:\n",
    "    st.subheader(f\"{feature} - 7-Day Forecast\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df['Day'], df[feature], marker='o')\n",
    "    ax.set_title(f\"{feature} over the Next 7 Days\")\n",
    "    ax.set_xlabel(\"Day\")\n",
    "    ax.set_ylabel(feature)\n",
    "    ax.grid(True)\n",
    "    st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2bad1c0-d30e-4b99-9625-32bd3f3430dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 20:01:07.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.795 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 20:01:07.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === App Title ===\n",
    "st.title(\"📊 7-Day Weather Forecast Dashboard\")\n",
    "st.markdown(\"This dashboard visualizes forecasted weather data from your cleaned dataset.\")\n",
    "\n",
    "# === Load Data ===\n",
    "uploaded_file = st.file_uploader(\"📁 Upload the forecast CSV file\", type=[\"csv\"])\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "\n",
    "    st.success(\"✅ File loaded successfully!\")\n",
    "\n",
    "    # === Show Columns ===\n",
    "    st.subheader(\"📋 Columns in the dataset\")\n",
    "    st.write(df.columns.tolist())\n",
    "\n",
    "    # === Check for 'Day' or 'Date' column ===\n",
    "    if 'Day' in df.columns:\n",
    "        x_axis = df['Day']\n",
    "        x_label = \"Day\"\n",
    "    elif 'Date' in df.columns:\n",
    "        x_axis = df['Date']\n",
    "        x_label = \"Date\"\n",
    "    else:\n",
    "        st.error(\"❌ Neither 'Day' nor 'Date' column is present in the dataset.\")\n",
    "        st.stop()\n",
    "\n",
    "    # === Feature Columns ===\n",
    "    excluded_columns = ['Day', 'Date']\n",
    "    features = [col for col in df.columns if col not in excluded_columns]\n",
    "\n",
    "    # === Plot each feature ===\n",
    "    for feature in features:\n",
    "        st.subheader(f\"📈 {feature} — 7-Day Forecast\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x_axis, df[feature], marker='o', linestyle='-')\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(feature)\n",
    "        ax.set_title(f\"{feature} over the Next 7 Days\")\n",
    "        ax.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "else:\n",
    "    st.warning(\"📂 Please upload a forecasted CSV file to begin.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dd973-ecfc-4e5a-b370-cb6ddaeb2202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
